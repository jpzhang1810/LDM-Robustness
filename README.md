# On the Robustness of Latent Diffusion Models
Pytorch implementation for the pilot study on the robustness of latent diffusion models.

- This repository provides a high-quality dataset for fairly comparing different attacking algorithms on diffusion models.

- This repository contains the code for automatically building the dataset from coco dataset.

- This repository illustrates a pilot study on the robustness of latent diffusion models, including: module vulnerability, transferability across models and prompts, robustness of adversarial examples.

We hope this repository can boost the research on the robustness of latent diffusion models.

**[On the Robustness of Latent Diffusion Models](https://arxiv.org/pdf/2306.08257.pdf)**

## Requirements

- Python 3.8.16
- Pytorch 2.0.0
- Torchvision 0.15.1
- Numpy 1.23.5
- Pillow 9.4.0
- Scipy 1.9.1
- Accelerate 0.18.0
- Diffusers 0.14.0
- Torchmetrics
- Torch-fidelity


#### Introduction


- `data_construction` : the pipelines for the dataset construction from the coco dataset.

- `dataset` : the dataset for testing the robustness of latent diffusion models, especially the image editing task. The dataset includes 850 data pairs (image+prompt) for image variation models and 715 data triplets (image+prompt+mask) for image inpainting models.

- `diffusersgrad` : a modified version of the official diffuser library. This modified version allows backward gradient computation and disables the safety checker.

- `attack_variation.ipynb` : the code for generating adversarial examples by attacking different modules of image variation diffusion models.

- `variation_generation.ipynb` : the code for generating edited images of image variation diffusion models with the input of adversarial images and prompts.

- `variation_evaluation.ipynb` : the code for evaluating the generated images of image variation diffusion models.

- `attack_inpainting.ipynb` : the code for generating adversarial examples by attacking different modules of image inpainting diffusion models.

- `inpainting_generation.ipynb` : the code for generating edited images of image inpainting diffusion models with the input of adversarial images and prompts.

- `inpainting_evaluation.ipynb` : the code for evaluating the generated images of image inpainting diffusion models.


## Experiments


#### Generate adversarial examples by attacking different modules

- `attack_variation.ipynb` and `attack_inpainting.ipynb`

Try attacking different modules inside diffusion models by uncommenting the code in register function. 

You can also play with the register function to attack other modules.


#### Generate edited images

- `variation_generation.ipynb` and `inpainting_generation.ipynb`

You could change the choice of the diffusion model in the generation process to acquire model-transfer generated images and change the input prompt to achieve prompt-transfer generated images.


#### Evaluate the generation

- `variation_evaluation.ipynb` and `inpainting_evaluation.ipynb`


## Dataset

#### Dataset introduction

The released dataset includes 850 data pairs for image variation models and 715 triplets for image inpainting models after human evaluation. Since the diffusion attack is time-consuming, so we only consider testing the robustness on 500 data pairs and triplets.

- `dataset/images` : selected 170 images for image variation models.

- `dataset/images_crop` : selected 143 cropped images for image inpainting models.

- `dataset/mask_crop` : selected 143 cropped images for image inpainting models.

- `dataset/prompts.json` : edited prompts generated by ChatGPT and 5 prompts per images.

- `dataset/select_ids.txt` : record of the mapping between image name and idx. 


#### Generate customized dataset

If you would like to generate your own dataset on coco, you can download the [data](http://images.cocodataset.org/zips/val2017.zip) and put it in `data_construction/coco`.

- `data_construction/select_image.ipynb` : code for selecting high-quality images from the coco validation set by CLIP score.

- `data_construction/filter_prompts.ipynb` : code for selecting high-quality ChatGPT generated prompts by CLIP score.

- `data_construction/generate_mask_filter_image.ipynb` : code for extracting main entity, obtaining the mask, and resizing the images.



## Citing this work

If you find this work is useful in your research, please consider citing:

```
@article{zhang2023robustness,
  title={On the Robustness of Latent Diffusion Models},
  author={Zhang, Jianping and Xu, Zhuoer and Cui, Shiwen and Meng, Changhua and Wu, Weibin and Lyu, Michael R},
  journal={arXiv preprint arXiv:2306.08257},
  year={2023}
}
```

## Acknowledgments

Code refer to: [Raising the Cost of Malicious AI-Powered Image Editing](https://github.com/MadryLab/photoguard).
