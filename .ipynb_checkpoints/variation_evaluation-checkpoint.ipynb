{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f7ba20-f47e-49cf-9eac-cba485648a1a",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "",
     "shell.execute_reply.started": "",
     "to_execute": "2023-05-16T11:40:19.625Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES\n",
      "000000276284.jpg\n",
      "dict_keys(['info', 'licenses', 'images', 'annotations', 'categories'])\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "from PIL import Image, ImageOps\n",
    "import requests\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import torch\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from io import BytesIO\n",
    "from diffusersgrad import StableDiffusionImg2ImgPipeline\n",
    "import torchvision.transforms as T\n",
    "from torchmetrics.multimodal import *\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "from torchmetrics.image.inception import InceptionScore\n",
    "from torchmetrics.image import PeakSignalNoiseRatio\n",
    "from torchmetrics.image import MultiScaleStructuralSimilarityIndexMeasure\n",
    "from torchmetrics.image import StructuralSimilarityIndexMeasure\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "\n",
    "from utils import preprocess, recover_image\n",
    "to_pil = T.ToPILImage()\n",
    "\n",
    "with open(\"dataset/prompts.json\", \"r\") as f:\n",
    "    prompts_dict = json.load(f)\n",
    "image_names = list(prompts_dict.keys())\n",
    "\n",
    "image_idxs = [0,6,7,10,13,17,20,21,25,27,32,34,35,36,38,39,40,44,46,47,48,49,51,54,55,57,59,67,68,70,72,77,78,79,\n",
    "80,81,82,84,87,89,92,94,96,97,98,103,104,107,108,111,112,114,115,116,119,120,123,124,128,129,132,134,\n",
    "139,140,141,143,144,151,154,155,158,159,165,172,173,175,176,177,178,180,182,184,185,186,187,189,190,192,195,\n",
    "197,198,200,201,204,206,208,209,211,212,213,214,215,218,219,222,224,227,230,231,237,239,240,241,244,249,252,\n",
    "253,254,257,263,264,265,266,268,269,271,275,278,281,282,286,289,294,296,298,303,304,305,306,309,314,318,319,\n",
    "320,322,323,331,332,334,335,341,343,345,349,350,353,355,360,361,370,373,375,376,377,383,393,394,395,397,398]\n",
    "\n",
    "# A fixed random selected seed in all the experiments\n",
    "SEED = 9209\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.PILToTensor()\n",
    "])\n",
    "\n",
    "metric = CLIPScore(model_name_or_path=\"openai/clip-vit-base-patch16\")\n",
    "fid = FrechetInceptionDistance()\n",
    "inception = InceptionScore()\n",
    "psnr = PeakSignalNoiseRatio(data_range=1.0)\n",
    "ms_ssim = MultiScaleStructuralSimilarityIndexMeasure(data_range=1.0)\n",
    "ssim = StructuralSimilarityIndexMeasure(data_range=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92450fb8-3400-4ae5-999b-b708c1c2800b",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2023-05-16T11:40:50.424905Z",
     "shell.execute_reply.started": "2023-05-16T11:40:50.422777Z",
     "to_execute": "2023-05-16T11:40:21.094Z"
    }
   },
   "outputs": [],
   "source": [
    "# Generated images by adversarial samples\n",
    "folder = \"data/variation/resnet_generate/\"\n",
    "# Generated images by original samples\n",
    "folder_ori_generate = \"data/variation/ori_image_generate/\"\n",
    "# Original images\n",
    "folder_ori = \"dataset/images/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8774d02-715e-4184-a258-a055bbcad49c",
   "metadata": {
    "execution": {
     "shell.execute_reply.end": "2023-05-16T13:49:50.812611Z",
     "shell.execute_reply.started": "2023-05-16T13:48:09.377779Z",
     "to_execute": "2023-05-16T13:48:08.988Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([500, 3, 512, 512])\n",
      "PSNR:  tensor(13.7023)\n"
     ]
    }
   ],
   "source": [
    "#PSNR\n",
    "total = 0\n",
    "scores = 0.0\n",
    "num = 100\n",
    "image_advs = []\n",
    "image_oris = []\n",
    "for i in range(num):\n",
    "    image_idx = image_idxs[i]\n",
    "    torch.cuda.empty_cache()\n",
    "    for j in range(5):\n",
    "        adv = Image.open(folder + image_names[image_idx][:-4] + \"_\" + str(j) + image_names[image_idx][-4:]).convert('RGB').resize((512,512))\n",
    "        ori = Image.open(folder_ori_generate + image_names[image_idx][:-4] + \"_\" + str(j) + image_names[image_idx][-4:]).convert('RGB').resize((512,512))\n",
    "        torch.manual_seed(SEED)\n",
    "        adv = np.array(adv).astype(np.float32)/255.0\n",
    "        adv = adv[None].transpose(0, 3, 1, 2)\n",
    "        image_adv = torch.from_numpy(adv)\n",
    "        image_advs.append(image_adv)\n",
    "        ori = np.array(ori).astype(np.float32)/255.0\n",
    "        ori = ori[None].transpose(0, 3, 1, 2)\n",
    "        image_ori = torch.from_numpy(ori)\n",
    "        image_oris.append(image_ori)\n",
    "\n",
    "image_advs = torch.concat(image_advs, dim=0)\n",
    "image_oris = torch.concat(image_oris, dim=0)\n",
    "print(image_advs.shape)\n",
    "torch.manual_seed(SEED)\n",
    "score = psnr(image_advs, image_oris)\n",
    "\n",
    "print(\"PSNR: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc4b034-a196-4448-8b40-5bfa5b71b035",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#FID\n",
    "total = 0\n",
    "scores = 0.0\n",
    "num = 100\n",
    "image_advs = []\n",
    "image_oris = []\n",
    "for i in range(num):\n",
    "    image_idx = image_idxs[i]\n",
    "    torch.cuda.empty_cache()\n",
    "    for j in range(5):\n",
    "        adv = Image.open(folder + image_names[image_idx][:-4] + \"_\" + str(j) + image_names[image_idx][-4:]).convert('RGB').resize((512,512))\n",
    "        ori = Image.open(folder_ori + image_names[image_idx]).convert('RGB').resize((512,512))\n",
    "        torch.manual_seed(SEED)\n",
    "        adv = np.array(adv).astype(np.uint8)\n",
    "        adv = adv[None].transpose(0, 3, 1, 2)\n",
    "        image_adv = torch.from_numpy(adv)\n",
    "        image_advs.append(image_adv)\n",
    "        ori = np.array(ori).astype(np.uint8)\n",
    "        ori = ori[None].transpose(0, 3, 1, 2)\n",
    "        image_ori = torch.from_numpy(ori)\n",
    "        image_oris.append(image_ori)\n",
    "\n",
    "image_advs = torch.concat(image_advs, dim=0)\n",
    "image_oris = torch.concat(image_oris, dim=0)\n",
    "print(image_advs.shape)\n",
    "fid.update(image_advs, real=False)\n",
    "fid.update(image_oris, real=True)\n",
    "torch.manual_seed(SEED)\n",
    "score = fid.compute()\n",
    "score = score.detach().cpu().numpy()\n",
    "print(\"FID: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6933c91b-9944-4d15-9ba3-3c8e118bb00d",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#IS\n",
    "total = 0\n",
    "scores = 0.0\n",
    "num = 100\n",
    "image_advs = []\n",
    "image_oris = []\n",
    "for i in range(num):\n",
    "    image_idx = image_idxs[i]\n",
    "    torch.cuda.empty_cache()\n",
    "    for j in range(5):\n",
    "        adv = Image.open(folder + image_names[image_idx][:-4] + \"_\" + str(j) + image_names[image_idx][-4:]).convert('RGB').resize((512,512))\n",
    "        ori = Image.open(folder_ori + image_names[image_idx]).convert('RGB').resize((512,512))\n",
    "        torch.manual_seed(SEED)\n",
    "        adv = np.array(adv).astype(np.uint8)\n",
    "        adv = adv[None].transpose(0, 3, 1, 2)\n",
    "        image_adv = torch.from_numpy(adv)\n",
    "        image_advs.append(image_adv)\n",
    "        ori = np.array(ori).astype(np.uint8)\n",
    "        ori = ori[None].transpose(0, 3, 1, 2)\n",
    "        image_ori = torch.from_numpy(ori)\n",
    "        image_oris.append(image_ori)\n",
    "\n",
    "image_advs = torch.concat(image_advs, dim=0)\n",
    "image_oris = torch.concat(image_oris, dim=0)\n",
    "print(image_advs.shape)\n",
    "inception.update(image_advs)\n",
    "torch.manual_seed(SEED)\n",
    "score = inception.compute()\n",
    "IS = score[0].detach().cpu().numpy()\n",
    "print(\"IS: \", IS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e962a27-6cb6-4321-87e2-a040f4f5e76f",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#SSIM\n",
    "ssim = StructuralSimilarityIndexMeasure(data_range=1.0)\n",
    "total = 0\n",
    "scores = 0.0\n",
    "num = 100\n",
    "image_advs = []\n",
    "image_oris = []\n",
    "for i in range(num):\n",
    "    image_idx = image_idxs[i]\n",
    "    torch.cuda.empty_cache()\n",
    "    for j in range(5):\n",
    "        adv = Image.open(folder + image_names[image_idx][:-4] + \"_\" + str(j) + image_names[image_idx][-4:]).convert('RGB').resize((512,512))\n",
    "        ori = Image.open(folder_ori_generate + image_names[image_idx][:-4] + \"_\" + str(j) + image_names[image_idx][-4:]).convert('RGB').resize((512,512))\n",
    "        torch.manual_seed(SEED)\n",
    "        adv = np.array(adv).astype(np.float32)\n",
    "        adv = adv[None].transpose(0, 3, 1, 2)\n",
    "        image_adv = torch.from_numpy(adv)\n",
    "        image_advs.append(image_adv)\n",
    "        ori = np.array(ori).astype(np.float32)\n",
    "        ori = ori[None].transpose(0, 3, 1, 2)\n",
    "        image_ori = torch.from_numpy(ori)\n",
    "        image_oris.append(image_ori)\n",
    "\n",
    "image_advs = torch.concat(image_advs, dim=0)\n",
    "image_oris = torch.concat(image_oris, dim=0)\n",
    "print(image_advs.shape)\n",
    "torch.manual_seed(SEED)\n",
    "score = ssim(image_advs, image_oris)\n",
    "\n",
    "print(\"SSIM: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3896c4-a193-4106-9b09-7e67bfe18cfa",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#MSSSIM\n",
    "msssim = MultiScaleStructuralSimilarityIndexMeasure(data_range=1.0)\n",
    "total = 0\n",
    "scores = 0.0\n",
    "num = 100\n",
    "image_advs = []\n",
    "image_oris = []\n",
    "for i in range(num):\n",
    "    image_idx = image_idxs[i]\n",
    "    torch.cuda.empty_cache()\n",
    "    for j in range(5):\n",
    "        adv = Image.open(folder + image_names[image_idx][:-4] + \"_\" + str(j) + image_names[image_idx][-4:]).convert('RGB').resize((512,512))\n",
    "        ori = Image.open(folder_ori_generate + image_names[image_idx][:-4] + \"_\" + str(j) + image_names[image_idx][-4:]).convert('RGB').resize((512,512))\n",
    "        torch.manual_seed(SEED)\n",
    "        adv = np.array(adv).astype(np.float32)\n",
    "        adv = adv[None].transpose(0, 3, 1, 2)\n",
    "        image_adv = torch.from_numpy(adv)\n",
    "        image_advs.append(image_adv)\n",
    "        ori = np.array(ori).astype(np.float32)\n",
    "        ori = ori[None].transpose(0, 3, 1, 2)\n",
    "        image_ori = torch.from_numpy(ori)\n",
    "        image_oris.append(image_ori)\n",
    "\n",
    "image_advs = torch.concat(image_advs, dim=0)\n",
    "image_oris = torch.concat(image_oris, dim=0)\n",
    "print(image_advs.shape)\n",
    "torch.manual_seed(SEED)\n",
    "score = msssim(image_advs, image_oris)\n",
    "\n",
    "print(\"MSSSIM: \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1a117d-50fc-4799-85a5-7b1e121b75c0",
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#CLIP Score\n",
    "total = 0\n",
    "scores = 0.0\n",
    "num = 100\n",
    "for i in range(num):\n",
    "    image_idx = image_idxs[i]\n",
    "    torch.cuda.empty_cache()\n",
    "    if total % 20 == 0:\n",
    "        print(total)\n",
    "    prompts = prompts_dict[image_names[image_idx]]\n",
    "    for j in range(5):\n",
    "        image = Image.open(folder + image_names[image_idx][:-4] + \"_\" + str(j) + image_names[image_idx][-4:]).convert('RGB').resize((512,512))\n",
    "        prompt = prompts[j]\n",
    "        torch.manual_seed(SEED)\n",
    "        score = metric(transform(image), prompt)\n",
    "        score = score.detach().cpu().numpy()\n",
    "        scores += score\n",
    "    total += 1\n",
    "print(scores/(num*5))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
